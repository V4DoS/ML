{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406d75d3-9dee-4d4c-b6d8-f9f804dbfb18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26853f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                          # Линейная Регрессия\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Генерируем случайные данные для регрессии\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(100, 1)\n",
    "y = X*np.random.rand(100, 1)\n",
    "\n",
    "# Разделяем данные на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Создаем модель линейной регрессии\n",
    "model = LinearRegression()\n",
    "\n",
    "# Обучаем модель на обучающем наборе данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Получаем предсказания на тестовом наборе данных\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Визуализируем данные и линию регрессии\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test, y_test, color='green')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Линейная Регрессия')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Оцениваем точность модели с помощью коэффициента детерминации\n",
    "r2 = r2_score(X_test, y_pred)\n",
    "print(\"Коэффициент детерминации (R^2):\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39671388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                         # Линейная Регрессия\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_excel('C:/Users/bondarenkovv/Desktop/Python/ML/test.xlsx')\n",
    "# Обучение модели линейной регрессии\n",
    "model = LinearRegression()\n",
    "model.fit(df[['Вес']], df['Количество_колес'])\n",
    "\n",
    "# Предсказание значений\n",
    "y_pred = model.predict(df[['Вес']])\n",
    "\n",
    "# Построение графика\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df.Вес, df.Количество_колес, color='red')\n",
    "plt.plot(df.Вес, y_pred, color='blue', linewidth=3)\n",
    "plt.xlabel('Вес')\n",
    "plt.ylabel('Количество колес')\n",
    "plt.title('Линейная Регрессия')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79985b4b-b3cf-407b-a8b9-ba951061ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Ваши данные\n",
    "X = np.array([55, 49, 51, 63, 48, 51, 49, 48, 46, 45, 48, 62, 55, 54, 52, 51, 55]).reshape(-1, 1)\n",
    "y = np.array([9, 8.7, 8.8, 10.5, 8.6, 10, 8.8, 8.7, 8.6, 8.5, 8.4, 10, 10.2, 9.1, 8.9, 8.7, 8.6])\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Создание и обучение модели\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовом наборе данных\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оценка модели с использованием различных метрик\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Вывод метрик\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "# Вывод предсказанных и истинных значений для сравнения\n",
    "print(\"Predicted values:\", y_pred)\n",
    "print(\"True values:\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e08ec-c4de-42f6-829c-49fe348275dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression    # Линейная Регрессия Рост Вес\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Данные\n",
    "height = [170, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
    "          180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190]\n",
    "weight = [54, 55, 60, 59, 68, 70, 65, 78, 82, 83,\n",
    "          80, 82, 81, 85, 90, 86, 88, 88, 89, 91, 94]\n",
    "\n",
    "# Преобразование в массив numpy\n",
    "X = np.array([height]).T  # .T используется для транспонирования массива\n",
    "y = np.array(weight)  # Мы используем рост в качестве зависимой переменной для примера\n",
    "\n",
    "# Создание и обучение модели\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Вывод коэффициентов регрессии\n",
    "print(\"Коэффициенты регрессии (w0, w1):\", model.intercept_, model.coef_)\n",
    "\n",
    "# Предсказание значений\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Вычисление метрик\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(\"Среднеквадратическая ошибка (MSE):\", mse)\n",
    "print(\"Коэффициент детерминации (R²):\", r2)\n",
    "\n",
    "# Построение графика\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(height, weight, color='green', label='Фактические данные')\n",
    "plt.plot(height, y_pred, color='red', linewidth=3, label='Линия регрессии')\n",
    "plt.xlabel('Рост')\n",
    "plt.ylabel('Вес')\n",
    "plt.title('Линейная Регрессия')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf3f3f3-c7ef-4952-8d66-37120d4b66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                            # Полиномиальная Регрессия Рост Вес(степень 4)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Данные\n",
    "height = [170, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
    "          180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190]\n",
    "weight = [54, 55, 60, 59, 68, 70, 65, 78, 82, 83,\n",
    "          80, 82, 81, 85, 90, 86, 88, 88, 89, 91, 94]\n",
    "\n",
    "# Преобразование в массив numpy\n",
    "X = np.array(height).reshape(-1, 1)\n",
    "y = np.array(weight)\n",
    "\n",
    "# Создание полиномиальных признаков (например, степени 2)\n",
    "poly_features = PolynomialFeatures(degree=6)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "# Создание и обучение модели линейной регрессии\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "\n",
    "# Предсказание значений\n",
    "y_pred = model.predict(X_poly)\n",
    "\n",
    "# Вычисление метрик\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(\"Среднеквадратическая ошибка (MSE):\", mse)\n",
    "print(\"Коэффициент детерминации (R²):\", r2)\n",
    "print(\"Коэффициенты регрессии (w0, w1, w2, w3):\", model.intercept_, model.coef_)\n",
    "# Построение графика\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(height, weight, color='green', label='Фактические данные')\n",
    "plt.plot(height, y_pred, color='red', linewidth=3, label='Полиномиальная регрессия (степень 4)')\n",
    "plt.xlabel('Рост')\n",
    "plt.ylabel('Вес')\n",
    "plt.title('Полиномиальная Регрессия')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03770d1-00f4-4df9-aba9-7fa29dab17ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                     # Метод наименьших квадратов( та же задача без sklearn)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Данные\n",
    "height = np.array([170, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
    "                   180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190])\n",
    "weight = np.array([54, 55, 60, 59, 68, 70, 65, 78, 82, 83,\n",
    "                   80, 82, 81, 85, 90, 86, 88, 88, 89, 91, 94])\n",
    "\n",
    "# Рассчитываем средние значения\n",
    "mean_x = np.mean(height)\n",
    "mean_y = np.mean(weight)\n",
    "\n",
    "# Рассчитываем коэффициенты\n",
    "numerator = np.sum((height - mean_x) * (weight - mean_y))\n",
    "denominator = np.sum((height - mean_x) ** 2)\n",
    "beta_1 = numerator / denominator\n",
    "beta_0 = mean_y - beta_1 * mean_x\n",
    "\n",
    "print(f\"Коэффициенты регрессии (beta_0, beta_1): {beta_0}, {beta_1}\")\n",
    "\n",
    "# Предсказанные значения\n",
    "weight_pred = beta_0 + beta_1 * height\n",
    "\n",
    "# Вычисление метрик\n",
    "mse = np.mean((weight - weight_pred) ** 2)\n",
    "r2 = 1 - (np.sum((weight - weight_pred) ** 2) / np.sum((weight - mean_y) ** 2))\n",
    "\n",
    "print(\"Среднеквадратическая ошибка (MSE):\", mse)\n",
    "print(\"Коэффициент детерминации (R²):\", r2)\n",
    "\n",
    "# Построение графика\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(height, weight, color='green', label='Фактические данные')\n",
    "plt.plot(height, weight_pred, color='red', linewidth=3, label='Линия регрессии')\n",
    "plt.xlabel('Рост')\n",
    "plt.ylabel('Вес')\n",
    "plt.title('Линейная Регрессия методом наименьших квадратов')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa253579-5952-417b-865e-0f4e11a56526",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Класификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560249cf-ad58-4812-8637-4fd0214cca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "z = np.linspace(-10, 10, 100)\n",
    "sigma = 1/(1+np.exp(-z))\n",
    "plt.plot(z, sigma)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.xlabel('$z$')\n",
    "\n",
    "_ = plt.title('График логистической функции $\\sigma(z)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed6341-ecc7-4665-9611-1f38cb1ba80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np                               # Логистическая Регрессия\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Время учебы в часах\n",
    "study_hours = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)\n",
    "\n",
    "# Сдал экзамен или нет (1 - сдал, 0 - не сдал)\n",
    "passed_exam = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Обучение модели логистической регрессии\n",
    "model = LogisticRegression()\n",
    "model.fit(study_hours, passed_exam)\n",
    "\n",
    "# Вывод коэффициентов регрессии\n",
    "print(\"Коэффициенты регрессии (β0, β1):\", model.intercept_, model.coef_)\n",
    "\n",
    "# Предсказание для новых данных (время учебы от 0 до 12 часов)\n",
    "study_hours_new = np.arange(0, 13).reshape(-1, 1)\n",
    "predictions = model.predict(study_hours_new)\n",
    "probabilities = model.predict_proba(study_hours_new)[:, 1]\n",
    "\n",
    "# Визуализация результатов\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(study_hours, passed_exam, color='blue', label='Данные')\n",
    "plt.plot(study_hours_new, probabilities, color='red', linewidth=3, label='Граница решения')\n",
    "plt.xlabel('Время учебы (часы)')\n",
    "plt.ylabel('Сдал экзамен (1) / Не сдал экзамен (0)')\n",
    "plt.title('Логистическая Регрессия: Предсказание сдачи экзамена')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6864cf6-96b8-4aee-88a2-e90ea8a50a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "#import utils\n",
    "\n",
    "\n",
    "features = np.array([[1,0],[0,2],[1,1],[1,2],[1,3],[2,2],[2,3],[3,2]])\n",
    "labels = np.array([0,0,0,0,1,1,1,1])\n",
    "\n",
    "def plot_points(features, labels):\n",
    "    X = np.array(features)\n",
    "    y = np.array(labels)\n",
    "    spam = X[np.argwhere(y==1)]\n",
    "    ham = X[np.argwhere(y==0)]\n",
    "    plt.scatter([s[0][0] for s in spam],\n",
    "                   [s[0][1] for s in spam],\n",
    "                   s = 100,\n",
    "                   color = 'cyan',\n",
    "                   edgecolor = 'k',\n",
    "                   marker = '^')\n",
    "    plt.scatter([s[0][0] for s in ham],\n",
    "                   [s[0][1] for s in ham],\n",
    "                   s = 100,\n",
    "                   color = 'red',\n",
    "                   edgecolor = 'k',\n",
    "                   marker = 's')\n",
    "    plt.xlabel('aack')\n",
    "    plt.ylabel('beep')\n",
    "    plt.legend(['happy','sad'])\n",
    "    \n",
    "def draw_line(a,b,c, starting=0, ending=3, **kwargs):\n",
    "    # Plotting the line ax + by + c = 0\n",
    "    x = np.linspace(starting, ending, 1000)\n",
    "    plt.plot(x, -c/b - a*x/b, **kwargs)\n",
    "\n",
    "plot_points(features, labels)  \n",
    "draw_line(1,1,-3.5)\n",
    "\n",
    "#utils.plot_points(features, labels)\n",
    "#utils.draw_line(1,1,-3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe98ec-600f-4e44-a287-f1a5ab3ed7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm                  # SVM\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Данные\n",
    "X = np.array([[2, 3], [1, 1], [2, 1], [3, 1], [4, 2], [1, 3]])\n",
    "y = np.array([1, 1, -1, -1, -1, 1])\n",
    "\n",
    "# Создание модели SVM с RBF ядром\n",
    "model = svm.SVC(kernel='rbf', gamma='scale')\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(X, y)\n",
    "\n",
    "# Визуализация данных и границ принятия решений\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', alpha=0.7)\n",
    "\n",
    "# Построение сетки для визуализации границ принятия решений\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "\n",
    "# Прогнозирование значений на сетке\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Визуализация границ принятия решений\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='bwr')\n",
    "plt.xlabel('Признак 1')\n",
    "plt.ylabel('Признак 2')\n",
    "plt.title('Границы принятия решений SVM с RBF ядром')\n",
    "plt.show()\n",
    "\n",
    "# Новые данные для прогнозирования\n",
    "X_new = np.array([[3, 2], [1, 3]])\n",
    "\n",
    "# Прогнозирование\n",
    "predictions = model.predict(X_new)\n",
    "print(f\"Прогнозы для новых данных: {predictions}\")\n",
    "\n",
    "# Прогнозы для новых данных: [ 1 -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a881bd9-38d4-4661-8816-893f818f16e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris                               # K-NN к ближайших соседей\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Обучение модели k-NN с Евклидовым расстоянием\n",
    "knn_euclidean = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_euclidean.fit(X_train, y_train)\n",
    "y_pred_euclidean = knn_euclidean.predict(X_test)\n",
    "accuracy_euclidean = accuracy_score(y_test, y_pred_euclidean)\n",
    "\n",
    "# Обучение модели k-NN с Манхэттенским расстоянием\n",
    "knn_manhattan = KNeighborsClassifier(n_neighbors=3, metric='manhattan')\n",
    "knn_manhattan.fit(X_train, y_train)\n",
    "y_pred_manhattan = knn_manhattan.predict(X_test)\n",
    "accuracy_manhattan = accuracy_score(y_test, y_pred_manhattan)\n",
    "\n",
    "print(f'Accuracy with Euclidean distance: {accuracy_euclidean}')\n",
    "print(f'Accuracy with Manhattan distance: {accuracy_manhattan}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af741a-3b16-494b-99b4-1ed85419b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups                          # Наивный Байес\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Загрузка данных\n",
    "data = fetch_20newsgroups(subset='all')\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Преобразование текстовых данных в числовые признаки\n",
    "vectorizer = CountVectorizer()\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Обучение модели Наивного Байеса\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание и оценка\n",
    "y_pred = nb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e1907-21de-415d-8ee2-bc3ef8a331ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4eb8d9-6c4e-4b39-a6ad-3f174c9cca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                        #KMeans   3 Кластеров ( Центроиды и Евклидово растояние до точки.\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Генерация синтетических данных о клиентах (возраст, доход)\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(100, 2) * [50, 100000] + [20, 20000]  # Возраст от 20 до 70 лет, доход от 20k до 120k\n",
    "\n",
    "# Преобразование данных в DataFrame\n",
    "df = pd.DataFrame(data, columns=['Age', 'Income'])\n",
    "\n",
    "# Применение K-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(df[['Age', 'Income']])\n",
    "\n",
    "# Визуализация результатов\n",
    "plt.scatter(df['Age'], df['Income'], c=df['Cluster'], cmap='viridis')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Income')\n",
    "plt.title('Customer Segmentation')\n",
    "plt.show()\n",
    "\n",
    "# Метрики качества кластеризации\n",
    "silhouette_avg = silhouette_score(df[['Age', 'Income']], df['Cluster'])\n",
    "db_index = davies_bouldin_score(df[['Age', 'Income']], df['Cluster'])\n",
    "ch_index = calinski_harabasz_score(df[['Age', 'Income']], df['Cluster'])\n",
    "\n",
    "print(\"K-Means Silhouette Score: \", silhouette_avg)\n",
    "print(\"K-Means Davies-Bouldin Index: \", db_index)\n",
    "print(\"K-Means Calinski-Harabasz Index: \", ch_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae99717b-f61e-4fe8-87e8-11e23621b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                               #DBSCAN (Радиус, корневые и крайние точки + шум )\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Генерация синтетических данных (два полумесяца)\n",
    "X, _ = make_moons(n_samples=200, noise=0.1, random_state=42)\n",
    "\n",
    "# Применение DBSCAN\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X)\n",
    "\n",
    "# Визуализация результатов\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='turbo')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n",
    "print(\"DBSCAN Silhouette Score: \", silhouette_score(X, clusters))\n",
    "print(\"DBSCAN Davies-Bouldin Index: \", davies_bouldin_score(X, clusters))\n",
    "print(\"DBSCAN Calinski-Harabasz Index: \", calinski_harabasz_score(X, clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07302f88-98bb-4d69-a2ff-8c4037a682a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                           #HDBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import hdbscan\n",
    "\n",
    "# Генерация данных make_moons\n",
    "X, _ = make_moons(n_samples=200, noise=0.1, random_state=42)\n",
    "\n",
    "# Применение HDBSCAN\n",
    "hdbscan_clusterer = hdbscan.HDBSCAN(min_cluster_size=5)\n",
    "labels = hdbscan_clusterer.fit_predict(X)\n",
    "\n",
    "# Визуализация данных и результатов кластеризации\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='turbo', s=50)\n",
    "plt.title('HDBSCAN Clustering on make_moons Data')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n",
    "print(\"HDBSCAN Silhouette Score: \", silhouette_score(X, labels))\n",
    "print(\"HDBSCAN Davies-Bouldin Index: \", davies_bouldin_score(X, labels))\n",
    "print(\"HDBSCAN Calinski-Harabasz Index: \", calinski_harabasz_score(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2290826-e8df-49cf-9081-7dc1853c57b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np                      #PCA\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Создание случайного набора данных\n",
    "np.random.seed(0)\n",
    "data = np.random.rand(100, 5)\n",
    "df = pd.DataFrame(data, columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])\n",
    "\n",
    "# Центрирование данных\n",
    "df_centered = df - df.mean()\n",
    "\n",
    "# Применение PCA\n",
    "pca = PCA(n_components=2)  # Проекция на 2 главные компоненты\n",
    "principal_components = pca.fit_transform(df_centered)\n",
    "\n",
    "# Создание DataFrame с результатами PCA\n",
    "df_pca = pd.DataFrame(data=principal_components, columns=['Principal Component 1', 'Principal Component 2'])\n",
    "\n",
    "# Вывод объясненной дисперсии\n",
    "print(\"Объясненная дисперсия главных компонент:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Визуализация данных в новом пространстве\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df_pca['Principal Component 1'], df_pca['Principal Component 2'])\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA: Проекция данных на первые две главные компоненты')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f86ba-fec5-401b-a45d-44c0cc8b1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                       #LCA\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Пример текстовых данных\n",
    "documents = [\n",
    "    \"Привет мама,я иду домой\",\n",
    "    \"Привет папа,рад тебя видеть\",\n",
    "    \"Я очень люблю своих маму и папу\",\n",
    "    \"Мы с мамой и папой очень дружная семья\"\n",
    "]\n",
    "\n",
    "# Создание матрицы термов-документов с использованием TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Применение SVD для снижения размерности\n",
    "svd = TruncatedSVD(n_components=2)  # Проекция на пространство с двумя измерениями\n",
    "X_reduced = svd.fit_transform(X)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Матрица термов-документов (TF-IDF):\")\n",
    "print(pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out()))\n",
    "\n",
    "print(\"\\nМатрица после применения SVD:\")\n",
    "print(X_reduced)\n",
    "\n",
    "print(\"\\nТермины:\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nКомпоненты SVD:\")\n",
    "print(svd.components_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf6a18-5b0c-4aaa-a0b9-0bfe3c95845d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Градиентный бустинг/спуск.Продвинутые Ансамбли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb2206-da40-4f15-bc3e-14e096b4ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                       #  Градиент\n",
    "# Определяем целевую функцию и её градиент\n",
    "def f(theta):\n",
    "    return theta**2\n",
    "\n",
    "def gradient_f(theta):\n",
    "    return 2 * theta\n",
    "\n",
    "# Начальные параметры\n",
    "theta = 1.0  # Начальное значение\n",
    "learning_rate = 0.1  # Шаг обучения\n",
    "num_iterations = 10  # Количество итераций\n",
    "\n",
    "# Градиентный спуск\n",
    "for i in range(num_iterations):\n",
    "    grad = gradient_f(theta)\n",
    "    theta -= learning_rate * grad\n",
    "    # Печать текущего значения функции и параметра\n",
    "    print(f\"Iteration {i+1}: theta = {theta}, f(theta) = {f(theta)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df869fe3-7f04-497e-b007-7964137e78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Определяем целевую функцию и её градиент\n",
    "def f(theta):\n",
    "    return theta**2\n",
    "\n",
    "def gradient_f(theta):\n",
    "    return 2 * theta\n",
    "\n",
    "# Начальные параметры\n",
    "theta = 1.0  # Начальное значение\n",
    "learning_rate = 0.1  # Шаг обучения\n",
    "num_iterations = 10  # Количество итераций\n",
    "\n",
    "# Сохранение значений theta и f(theta) для отображения\n",
    "theta_values = []\n",
    "f_values = []\n",
    "\n",
    "# Градиентный спуск\n",
    "for i in range(num_iterations):\n",
    "    grad = gradient_f(theta)\n",
    "    theta_values.append(theta)\n",
    "    f_values.append(f(theta))\n",
    "    theta -= learning_rate * grad\n",
    "\n",
    "# График функции и траектории градиентного спуска\n",
    "theta_range = np.linspace(-1.5, 1.5, 400)\n",
    "f_range = f(theta_range)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(theta_range, f_range, label='$f(\\\\theta) = \\\\theta^2$', color='g')\n",
    "plt.scatter(theta_values, f_values, color='red')\n",
    "plt.plot(theta_values, f_values, color='red', linestyle='--', marker='o', label='Gradient Descent Path')\n",
    "plt.title('Gradient Descent on $f(\\\\theta) = \\\\theta^2$')\n",
    "plt.xlabel('$\\\\theta$')\n",
    "plt.ylabel('$f(\\\\theta)$')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699debe3-2397-4b40-8d2c-4ed6e05e443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb                        #lightgbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Более расширенный пример данных для обучения модели\n",
    "data = {\n",
    "    'Age':           [25, 35, 45, 50, 30, 55, 65, 20, 40, 70, 34, 29, 49, 52, 31, 57, 68, 23, 41, 72],\n",
    "    'BMI':           [22, 28, 24, 31, 26, 29, 33, 21, 27, 32, 30, 23, 25, 34, 28, 30, 36, 20, 26, 35],\n",
    "    'Glucose_Level': [90, 120, 100, 150, 110, 95, 140, 80, 105, 130, 115, 85, 102, 145, 112, 97, 138, 78, 108, 125],\n",
    "    'Diabetes':      [0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1]  # 1 - Диабет, 0 - Нет диабета\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Разделяем на признаки и целевую переменную\n",
    "X = df.drop('Diabetes', axis=1)\n",
    "y = df['Diabetes']\n",
    "\n",
    "# Разделяем на обучающий и тестовый наборы данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Преобразуем данные в формат, совместимый с LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "# Определяем параметры модели\n",
    "parameters = {\n",
    "    'objective': 'binary',  # бинарная классификация\n",
    "    'metric': 'binary_logloss',  # логарифмическая функция потерь\n",
    "    'boosting': 'gbdt',  # градиентный бустинг решающих деревьев\n",
    "    'learning_rate': 0.1,  # коэффициент обучения\n",
    "    'num_leaves': 31,  # максимальное количество листьев в дереве\n",
    "    'max_depth': -1,  # максимальная глубина дерева (-1 для отсутствия ограничений)\n",
    "    'min_data_in_leaf': 5,  # минимальное количество объектов в листе\n",
    "    'verbosity': -1  # уровень подробности вывода (чем меньше, тем меньше вывода)\n",
    "}\n",
    "\n",
    "# Обучаем модель\n",
    "num_round = 100  # количество итераций обучения\n",
    "bst = lgb.train(parameters, train_data, num_round)\n",
    "\n",
    "# Функция для предсказания на основе введённых данных\n",
    "def predict_diabetes(age, bmi, glucose_level):\n",
    "    new_data = pd.DataFrame({'Age': [age], 'BMI': [bmi], 'Glucose_Level': [glucose_level]})\n",
    "    prediction = bst.predict(new_data)[0]\n",
    "    return prediction\n",
    "\n",
    "# Ввод данных пользователем\n",
    "age = int(input(\"Введите возраст: \"))\n",
    "bmi = float(input(\"Введите индекс массы тела (BMI): \"))\n",
    "glucose_level = float(input(\"Введите уровень глюкозы: \"))\n",
    "\n",
    "# Предсказание и вывод результата\n",
    "prediction = predict_diabetes(age, bmi, glucose_level)\n",
    "diagnosis = \"Диабет\" if prediction >= 0.5 else \"Нет диабета\"\n",
    "if diagnosis ==\"Диабет\":\n",
    "    probability = prediction *100\n",
    "else:\n",
    "    probability = 100-(prediction *100)\n",
    "\n",
    "print(f\"Диагноз: {diagnosis} с вероятностью {probability:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49d3df-d5e3-4c03-b70d-3219852085fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек                 CatBoost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Создание искусственного набора данных\n",
    "data = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 70, 1000),\n",
    "    'income': np.random.randint(30000, 150000, 1000),\n",
    "    'marital_status': np.random.choice(['single', 'married', 'divorced'], 1000),\n",
    "    'employment_type': np.random.choice(['employed', 'unemployed', 'self-employed'], 1000),\n",
    "    'education': np.random.choice(['higher', 'secondary', 'none'], 1000),\n",
    "    'housing': np.random.choice(['rent', 'own'], 1000),\n",
    "    'defaulted': np.random.choice([0, 1], 1000)  # Целевая переменная\n",
    "})\n",
    "\n",
    "# Отделение целевой переменной от признаков\n",
    "X = data.drop('defaulted', axis=1)\n",
    "y = data['defaulted']\n",
    "\n",
    "# Определение категориальных признаков\n",
    "categorical_features = ['marital_status', 'employment_type', 'education', 'housing']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Инициализация и обучение модели CatBoostClassifier\n",
    "model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, loss_function='Logloss', verbose=250)\n",
    "model.fit(X_train, y_train, cat_features=categorical_features)\n",
    "\n",
    "# Прогнозирование на тестовом наборе данных\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оценка точности модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b17a4-4707-4bab-b11e-123a38e94379",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## NLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dac3fb6-fe04-4a08-9025-641581503ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bondarenkovv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bondarenkovv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bondarenkovv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bondarenkovv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\bondarenkovv\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  # Токенизатор\n",
    "nltk.download('averaged_perceptron_tagger')  # Теггер частей речи\n",
    "nltk.download('wordnet')  # Лексическая база данных WordNet\n",
    "nltk.download('stopwords')  # Часто встречающиеся слова\n",
    "\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e50f82c-21fc-4dc0-9f29-81379fbb018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: ['Привет', 'мамуля', '!', 'как', 'у', 'тебя', 'делишки', '?', 'А', 'у', 'нас', 'потихоньку', 'running']\n",
      "Sentences: ['Привет мамуля!', 'как у тебя делишки?', 'А у нас потихоньку running']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize       #Токенизация \n",
    "\n",
    "text = \"Привет мамуля! как у тебя делишки? А у нас потихоньку\"\n",
    "words = word_tokenize(text)\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "print(\"Words:\", words)\n",
    "print(\"Sentences:\", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a538cc-2f71-42cb-9cf6-ca41bff74b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords   #Удаление стоп-слов \n",
    "\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "print(\"Filtered Words:\", filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26e2deec-5aa9-4d43-afeb-97156949c00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Words: ['Привет', 'мамуля', '!', 'как', 'у', 'тебя', 'делишки', '?', 'А', 'у', 'нас', 'потихоньку', 'running']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer  #Лемматизация \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "print(\"Lemmatized Words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b75045a-cc55-45ea-8f50-6105f2655f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer   #Стемминг\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "print(\"Stemmed Words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea4b473-321f-4e4a-abbe-ec167e1623a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer #Векторизация \n",
    "\n",
    "documents = [\n",
    "    \"Привет мамуля! Как у тебя делишки, А у нас потихоньку.\",\n",
    "    \"Привет! Как у тебя дела?\",\n",
    "    \"Мамуля у нас все хорошо.\",\n",
    "    \"Привет, мамуля! Как у тебя?\"\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02aabdd-8f94-4b1c-98b1-7280fc56a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer #Векторизация \n",
    "\n",
    "# Наши предложения\n",
    "documents = [\n",
    "    \"Привет мамуля! Как у тебя делишки, А у нас потихоньку.\",\n",
    "    \"Привет! Как у тебя дела?\",\n",
    "    \"Мамуля у нас все хорошо.\",\n",
    "    \"Привет, мамуля! Как у тебя?\"\n",
    "]\n",
    "\n",
    "# Инициализируем TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Преобразуем наши документы в матрицу TF-IDF\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Получаем список всех слов (токенов)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Выводим результат\n",
    "import pandas as pd\n",
    "\n",
    "# Преобразуем матрицу TF-IDF в DataFrame для наглядности\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742153a2-2e0c-4d25-8a50-a4efae932f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel  # BERT\n",
    "import torch\n",
    "\n",
    "# Загрузка модели и токенизатора\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Пример текста\n",
    "text = \"Привет, как дела?\"\n",
    "\n",
    "# Токенизация текста\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Получение эмбеддингов\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "print(last_hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7f032-6662-4600-8db2-9972f781b964",
   "metadata": {},
   "source": [
    "# Нейронка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88f358-bd05-40c6-b6c3-b4690e9ae327",
   "metadata": {},
   "source": [
    "<img src=\"Progress.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce122172-9322-40e2-8c74-b6fb675319f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Создание DataFrame\n",
    "data = {\n",
    "    'Кашель':               [0, 1, 1, 1, 1, 0, 0, 0],\n",
    "    'Температура':          [1, 1, 0, 1, 0, 1, 1, 0],\n",
    "    'Затруднённое дыхание': [1, 0, 1, 1, 0, 1, 0, 0],\n",
    "    'Усталость':            [1, 1, 1, 0, 1, 0, 0, 1],\n",
    "    'Диагноз':              [1, 1, 1, 1, 0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "X = df.drop('Диагноз', axis=1)\n",
    "y = df['Диагноз']\n",
    "\n",
    "# Создание нейронной сети\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=4, activation='relu', kernel_regularizer=l2(0.01))) # Скрытый слой с 16 нейронами/регуляризация Л2\n",
    "model.add(Dense(8, activation='relu', kernel_regularizer=l2(0.01))) # Дополнительный скрытый слой с 8 нейронами, функция активация и Регуляризация\n",
    "model.add(Dense(1, activation='sigmoid'))  # Выходной слой\n",
    "\n",
    "# Компиляция модели с оптимизатором SGD (Градиентный спукс /Stochastic Gradient Descent)\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9)  # lr - скорость обучения, momentum - момент\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy','Precision'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(X, y, epochs=250, batch_size=10, verbose=0)\n",
    "\n",
    "# Вывод метрик на последней эпохе\n",
    "print(\"Метрики на последней эпохе:\")\n",
    "print(\"Loss:\", history.history['loss'][-1])\n",
    "print(\"Accuracy:\", history.history['accuracy'][-1])\n",
    "print(\"Precision:\", history.history['Precision'][-1])\n",
    "\n",
    "# Функция для получения симптомов от пользователя\n",
    "def get_symptoms():\n",
    "    cough = input(\"Есть ли у пациента кашель? (y/n): \")\n",
    "    fever = input(\"Есть ли у пациента температура? (y/n): \")\n",
    "    breathing_difficulty = input(\"Есть ли у пациента затрудненное дыхание? (y/n): \")\n",
    "    tiredness = input(\"Есть ли у пациента усталость? (y/n): \")\n",
    "    \n",
    "    # Преобразование ввода пользователя в числовые значения\n",
    "    symptoms = {\n",
    "        'Кашель': 1 if cough.lower() == 'y' else 0,\n",
    "        'Температура': 1 if fever.lower() == 'y' else 0,\n",
    "        'Затруднённое дыхание': 1 if breathing_difficulty.lower() == 'y' else 0,\n",
    "        'Усталость': 1 if tiredness.lower() == 'y' else 0,\n",
    "    }\n",
    "    symptoms_df = pd.DataFrame([symptoms])\n",
    "    return symptoms_df\n",
    "\n",
    "# Получение симптомов и прогнозирование\n",
    "symptoms = get_symptoms()\n",
    "\n",
    "# Прогнозирование с помощью обученной модели\n",
    "prediction = model.predict(symptoms)\n",
    "\n",
    "# Вывод диагноза и вероятности\n",
    "probability = prediction[0][0]\n",
    "if probability > 0.5:\n",
    "    print(f\"Диагноз: Болен (вероятность {probability:.2%})\")\n",
    "else:\n",
    "    print(f\"Диагноз: Здоров (вероятность {(1-probability):.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a37d73-d687-42a3-9f96-e6a97c1326d2",
   "metadata": {},
   "source": [
    "<img src=\"neuro1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08ffcc-606e-4032-827b-cef673b47b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def predict(x1, x2):\n",
    "  # Скрытый слой\n",
    "  hidden1 = sigmoid(x1 * (1) + x2 * (-2) - 1)\n",
    "  hidden2 = sigmoid(x1 * (-1) + x2 * (3) - 1)\n",
    "\n",
    "  # Выходной слой\n",
    "  output = sigmoid(hidden1 * (-1) + hidden2 * (2) + 1)\n",
    "  return output\n",
    "\n",
    "# Входные данные (1, 1)\n",
    "result = predict(1, 1)\n",
    "print(f\"Прогноз сети: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09cf1d5-7efe-4103-9fae-4256da776164",
   "metadata": {},
   "source": [
    "## Архитектуры сетей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885eeba4-f7b3-41fa-81d6-e0e085be2a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_dim, 100)\n",
    "        self.hidden2 = nn.Linear(100, 50)\n",
    "        self.output = nn.Linear(50, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden1(x))\n",
    "        x = self.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb1795-8964-4914-b748-60b8d17facac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), hidden_dim).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e894c33-07ac-4898-967b-16da0a5f8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FNN, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_dim, 128)\n",
    "        self.hidden2 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 10)  # Например, 10 классов для классификации\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden1(x))\n",
    "        x = self.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Пример использования\n",
    "model = FNN(input_dim=784)  # Например, для классификации изображений 28x28 (784 пикселя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c457eb-dca2-4e67-b4b7-4a26c3daf8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # Например, 10 классов для классификации\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Разворачивание тензора\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Пример использования\n",
    "model = CNN()  # Например, для классификации изображений 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6185bee-ad26-4c64-90a2-d5663e75fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Генератор\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(noise_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.tanh(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Дискриминатор\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Пример использования\n",
    "noise_dim = 100\n",
    "image_dim = 28 * 28  # Например, для изображений 28x28\n",
    "\n",
    "generator = Generator(noise_dim=noise_dim, output_dim=image_dim)\n",
    "discriminator = Discriminator(input_dim=image_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601ca10-9291-4b4c-9c64-06daa2b01bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
